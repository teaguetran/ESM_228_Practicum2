---
title: "ESM 228 wtf am i doing"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

I made this based on the cluster sampling example that was provided by Mark. This means that we take data from various clusters. For our example, it would be companies. I assume that there are 5 companies that work within the Sandy River Watershed that contains certain amounts of contractors in there. Rather than email every single contractor out there, this method goes to the company, which then would distribute our survey to each individual contractor for a OPTIONAL training for BMP. My code is pretty rough right now, but it works because I used Mark's. 

```{r load, echo=FALSE}
# Load the required packages
library(DeclareDesign)
library(knitr)
library(ggplot2)
library(grid)
library(gridExtra)
library(dplyr)
library(kableExtra)
```
git config --global user.name "teaguetran"
```{r pop}
set.seed(228)
population <- declare_population(
  companies = add_level(N=5, #5 companies 
         baseline=c(0.5, 0.3, 0.7, 0.8, 0.5)), #The proportion of contracators within those companies that will respond as "highly likely" or "somewhat likely" to do training. Remember, we take the scaled question and change it to binary
  contractors = add_level(N=c(100,150,75,125,50), #population of contractors in each company that we send the survey to
  attendance=draw_binary(baseline)) #estimate whether the person will attend training or not (1 = attend, 0 = will not attend)
 
)
pop <- population()
pop.vector <- c(100,150,75,125,50)

my_estimand <- declare_estimands(mean(attendance),
                                 label = "Ybar")
# We then declare out population. Out estimand is the mean level of attendance among the sample.

```

## DeclareDesign()

```{r report-samp}
# not too sure why Mark chose these specific numbers. Need to ask him. 
reporting <- declare_assignment(prob=0.8,
                  assignment_variable = "R")
#PH: declaring the assignment (or in this case, sampling) process.

sampling <- declare_sampling(strata=companies,
               strata_n=c(100, 100, 50,50,50))
#PH: saying that we want to sample by port, our strata. We're going to take 80 units from the first, second, third, and fourth ports, and then 8 units from the remaining ports.
```

```{r}
strata_weighted_mean <- function(data){
  data.frame(  
  estimator_label = "strata_w_mean",
  estimand_label = "Ybar",
  n = nrow(data),
  stringsAsFactors = FALSE,
  
  estimate = data %>% filter(R==1) %>% #PH: subset out units that are not sampled.
    group_by(companies) %>% 
    summarise(mean=mean(attendance)) %>%
    mutate(prop=pop.vector/sum(pop.vector)) %>% #PH: 'prop' is a variable calculating the proportion of units in the population that are at a given port.
    mutate(sub.mean=mean*prop) %>% pull(sub.mean) %>%  #PH: 'sub.mean' is a weighted average of the knowledge level within a given port.
    sum()) #PH: sums all the weighed averages of knowledge within ports to get a weighted sample mean.
} #just use this function, custom

#PH: here, we're declaring a second estimator that will estimate the population mean by calculating a strata weighted mean of the sample
```

```{r diagnosis, cache=TRUE}

answer <- declare_estimator(
  handler = tidy_estimator(strata_weighted_mean), #PH: this is the custom function we wrote in the chunk above.
  estimand = my_estimand) #PH: 'my_estimand' is the true population mean of knowledge. We happen to know this in this case (b/c we faked the data), but you'll have to make an educated guess about what this is in practice. Often, you see people designing M&E programs cite research to take a stab at the actual value of the estimand.

design <- population + my_estimand + reporting +
          sampling + answer
diagnosis <- diagnose_design(design, sims = 1000)

diagnosis$diagnosands_df[,c(4,5,12,14)] %>%
  kable()

```



































